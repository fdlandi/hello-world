# -*- coding: utf-8 -*-
"""mlp_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DrEP3uobI6f2fwWl5e2cvByBpg3Udzmt
"""

import matplotlib.pyplot as plt
import numpy as np

import torch
import torch.nn as nn
import torchvision

trainset = torchvision.datasets.MNIST(root='./data',
                                      train=True, 
                                      download=True,
                                      transform=torchvision.transforms.ToTensor())

testset = torchvision.datasets.MNIST(root='./data',
                                     train=False, 
                                     download=True,
                                     transform=torchvision.transforms.ToTensor())

def imshow(img):
  np_img = img.numpy()
  plt.imshow(np.transpose(np_img, (1, 2, 0)))
  plt.show()

batch_size = 4

trainloader = torch.utils.data.DataLoader(trainset,
                                          batch_size=batch_size,
                                          num_workers=0,
                                          shuffle=True)

testloader = torch.utils.data.DataLoader(testset,
                                         batch_size=batch_size,
                                         num_workers=0,
                                         shuffle=True)

dataiter = iter(trainloader)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images))
print(labels)

in_features, hidden_size_1, hidden_size_2, output_size = 28*28, 256, 64, 10

model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(in_features, hidden_size_1),
    nn.ReLU(),
    nn.Linear(hidden_size_1, hidden_size_2),
    nn.ReLU(),
    nn.Linear(hidden_size_2, output_size)
)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

num_epoch = 4
log_every = 5000

model.train()
for epoch in range(num_epoch):
  # reset epoch statistics
  running_loss = 0.0
  total, correct = 0.0, 0.0

  for i, data in enumerate(trainloader, 1):
    images, labels = data
    # gradients = 0
    optimizer.zero_grad()
    # forward pass + loss
    out = model(images)
    loss = loss_fn(out, labels)

    # backward + backprop
    loss.backward()
    optimizer.step()

    # update statistics
    _, pred = torch.max(out, 1)
    total += labels.shape[0]
    correct += (pred == labels).sum().item()
    running_loss += loss.item()

    # print info
    if i % log_every == 0:
      print('Epoch {} - Iter {} - Loss: {:.4f}'.format(epoch, i, running_loss))
      running_loss = 0.0

  print('Epoch {} - Accuracy: {:.2f}%'.format(epoch,
                                              100*correct/total))
  
print('Finished training')

dataiter = iter(testloader)
images, labels = dataiter.next()

model.eval()
out = model(images)
_, pred = torch.max(out, 1)

imshow(torchvision.utils.make_grid(images))
print('predette: {}'.format(pred))
print('corrette: {}'.format(labels))