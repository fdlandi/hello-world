# -*- coding: utf-8 -*-
"""Convnets_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ufNlwN79rz3L6qS8TmZKsWld33f0l126
"""

import matplotlib.pyplot as plt
import numpy as np
import sys

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as T

batch_size = 100

transform = T.Compose([
                       T.ToTensor(),
                       T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

print('Downloading dataset...')
trainset = torchvision.datasets.CIFAR100(root='./data',
                                         train=True,
                                         download=True,
                                         transform=transform)
testset = torchvision.datasets.CIFAR100(root='./data',
                                        train=False, 
                                        download=True,
                                        transform=transform)
print('Done!\n')

print('Creating dataloaders...')
trainloader = torch.utils.data.DataLoader(trainset,
                                          batch_size=batch_size,
                                          num_workers=4,
                                          shuffle=True)
testloader = torch.utils.data.DataLoader(testset,
                                         batch_size=batch_size,
                                         num_workers=4,
                                         shuffle=True)
print('Done!\n')

sizes = dict()
sizes['train'] = len(trainset)
sizes['test'] = len(testset)
classes = testset.classes

print('Dataset statistics:')
print('  Trainset size = {}'.format(sizes['train']))
print('  Testset size = {}'.format(sizes['test']))
print('  Number of classes = {}'.format(len(classes)))

print()
print('Samples:')

def imshow(img):
  np_img = img.numpy()
  plt.imshow(np.transpose(np_img, (1, 2, 0)))
  plt.show()

dataiter = iter(trainloader)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images[:8] / 2 + 0.5))
gt_labels = [classes[l] for l in labels[:8]]
print(gt_labels)

print()
print('Setting up device conf...')
if torch.cuda.is_available():
  device = torch.device('cuda:0')
else:
  device = torch.device('cpu')
print('Using device: {}'.format(device))

def progress_bar(iteration, total, length=50, prefix='', suffix=''):
  percentage = iteration / total
  completed = int(percentage * length)
  progress_bar = '|'+ '-'*completed + '>' + ' '*(length-completed)+'|'
  progress_perc = ' {:.2f}% '.format(100*percentage)
  return str(prefix + ' ' + progress_bar + progress_perc + suffix)

def predict(model, data, loss_fn):
  images, labels = data

  images = images.to(device)
  labels = labels.to(device)
  
  # forward pass: model makes prediction
  out = model(images)

  # computes loss and accuracy
  loss = loss_fn(out, labels)
  _, pred = torch.max(out, 1)
  total = labels.shape[0]
  correct = (pred == labels).sum().item()

  # returns statistics
  return loss, total, correct 

def train_epoch(model, optimizer, trainloader):
  # reset epoch statistics
  running_loss = 0.0
  total, correct = 0.0, 0.0
  it_per_epoch = len(trainloader)

  for iteration, data in enumerate(trainloader, 1):
    # training step
    optimizer.zero_grad()
    loss, total_step, correct_step = predict(model, data, loss_fn)
    loss.backward()
    optimizer.step()

    # update statistics
    total += total_step
    correct += correct_step
    running_loss += loss.item()

    # print info
    loss_msg = 'Running Loss: {:.4f}'.format(running_loss / iteration)
    print(progress_bar(iteration, it_per_epoch, suffix=loss_msg), end='\r')
    sys.stdout.flush()
  else:
    loss_msg = 'Epoch Loss: {:.4f}'.format(running_loss / it_per_epoch)
    print(progress_bar(it_per_epoch, it_per_epoch, suffix=loss_msg))

  return 100*correct/total

def evaluate(model, testloader):
  running_loss = 0.0
  total, correct = 0.0, 0.0
  it_test = len(testloader)

  for iteration, data in enumerate(testloader, 1):
    # forward function
    loss, total_step, correct_step = predict(model, data, loss_fn)

    # update statistics
    total += total_step
    correct += correct_step
    running_loss += loss.item()

    # print info
    loss_msg = 'Running Loss: {:.4f}'.format(running_loss / iteration)
    print(progress_bar(iteration, it_test, suffix=loss_msg), end='\r')
    sys.stdout.flush()
  else:
    loss_msg = 'Test Loss: {:.4f}'.format(running_loss / it_test)
    print(progress_bar(it_test, it_test, suffix=loss_msg))

  return 100*correct/total

class ConvBlock(nn.Module):
  # This is an implementation for a custom
  # [Conv + Norm + Relu]*2 + MaxPool block
  def __init__(self, channel_in, channel_h, channel_out,
               kernel_size=3, stride=1, padding=1, activation=nn.ReLU()):
    # __init__ method creates the instance of the class
    # all attributes are denoted with the self.'name' notation
    super(ConvBlock, self).__init__()
    self.conv1 = nn.Conv2d(channel_in, channel_h, kernel_size,
                           stride=stride, padding=padding)
    self.conv2 = nn.Conv2d(channel_h, channel_out, kernel_size,
                           stride=stride, padding=padding)
    # self.batch_norm_1 = nn.BatchNorm2d(num_features=channel_h)
    # self.batch_norm_2 = nn.BatchNorm2d(num_features=channel_out)
    self.activation = activation
    self.max_pool = nn.MaxPool2d((2,2))

  def forward(self, x):
    # the forward pass of the network is implemented in this method
    # here you can use the module created in the __init__() method
    # in this case, the input 'x' is sequentially forwarded to all the modules
    x = self.conv1(x)
    # x = self.batch_norm_1(x)
    x = self.activation(x)
    x = self.conv2(x)
    # x = self.batch_norm_2(x)
    x = self.activation(x)
    x = self.max_pool(x)
    return x

from typing import List

class MLP(nn.Module):
  # A custom implementation of a multi-layer perceptron with an arbitrary number of layers
  # one should specify a list of integer numbers
  # (e.g. [512, 256, 64, 10] or [1024, 100])
  def __init__(self, layer_size_list: List[int],
               activation=nn.ReLU(), drop_prob=None):
    super(MLP, self).__init__()
    sizes = layer_size_list
    self.fc_layers = nn.ModuleList(
            [nn.Linear(in_features=in_size, out_features=out_size)
              for in_size, out_size in zip(sizes[:-1], sizes[1:])]
          )
    self.activation = activation
    self.flatten = nn.Flatten()

    if drop_prob is None:
      self.dropout = None
    else:
      assert 0 < drop_prob < 1, 'Dropout probability must be in range (0,1)'
      self.dropout = nn.Dropout(p=drop_prob)

  def forward(self, x):
    # a more sophisticated forward function to deal with an arbitrary number of layers
    # in general, forward function can be arbitrarily complex
    x = self.flatten(x)

    for i, layer in enumerate(self.fc_layers):
      if self.dropout is not None and i != 0:
        x = self.dropout(x)
      x = layer(x)
      x = self.activation(x)

    return x

class AlexNet(nn.Module):
  def __init__(self):
    super(AlexNet, self).__init__()
    # conv1 + maxpool1
    self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, 
                           kernel_size=(11,11), stride=4, padding=0)
    self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=2)
    # conv2 + maxpool2
    self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, 
                           kernel_size=(5,5), stride=1, padding=2)    
    # conv3, conv4, conv5 + maxpool3
    self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, 
                           kernel_size=(3,3), stride=1, padding=1)
    self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, 
                           kernel_size=(3,3), stride=1, padding=1)
    self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, 
                           kernel_size=(3,3), stride=1, padding=1)
    # fc6, fc7, fc8
    self.fc6 = nn.Linear(in_features=6*6*256, out_features=4096)
    self.drop6 = nn.Dropout(p=0.5)
    self.fc7 = nn.Linear(in_features=4096, out_features=4096)
    self.drop7 = nn.Dropout(p=0.5)

    self.fc8 = nn.Linear(in_features=4096, out_features=1000)

    self.activation = nn.ReLU()
    self.flatten = nn.Flatten()

  def forward(self, x):
    x = self.conv1(x)
    x = self.activation(x)
    x = self.maxpool(x)

    x = self.activation(self.conv2(x))
    x = self.maxpool(x)

    x = self.activation(self.conv3(x))
    x = self.activation(self.conv4(x))
    x = self.activation(self.conv5(x))
    x = self.maxpool(x)

    x = self.flatten(x)
    x = self.activation(self.fc6(x))
    x = self.drop6(x)
    x = self.activation(self.fc7(x))
    x = self.drop7(x)
    
    x = self.fc8(x)

    return x

class VGG16(nn.Module):
  def __init__(self):
    super(VGG16, self).__init__()
    # block 1
    self.block1 = nn.Sequential(
        nn.Conv2d(in_channels=3, out_channels=64,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=64, out_channels=64,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    # block 2
    self.block2 = nn.Sequential(
        nn.Conv2d(in_channels=64, out_channels=128,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=128, out_channels=128,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    # block 3
    self.block3 = nn.Sequential(
        nn.Conv2d(in_channels=128, out_channels=256,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=256, out_channels=256,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    # block 4
    self.block4 = nn.Sequential(
        nn.Conv2d(in_channels=256, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=512, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=512, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    # block 5
    self.block5 = nn.Sequential(
        nn.Conv2d(in_channels=512, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=512, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=512, out_channels=512,
                  kernel_size=(3,3), stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    # fc
    self.fc = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=7*7*512, out_features=4096),
        nn.ReLU(),
        nn.Dropout(p=0.5),
        nn.Linear(in_features=4096, out_features=4096),
        nn.ReLU(),
        nn.Dropout(p=0.5),
        nn.Linear(in_features=4096, out_features=1000)
    )

  def forward(self, x):
    x = self.block1(x)
    x = self.block2(x)
    x = self.block3(x)
    x = self.block4(x)
    x = self.block5(x)
    x = self.fc(x)
    return x

class InceptionModule(nn.Module):
  def __init__(self, in_features, bottleneck_size=64):
    super(InceptionModule, self).__init__()
    # branch 1 -> conv 1x1
    self.conv1 = nn.Conv2d(in_channels=in_features, out_channels=128,
                           kernel_size=(1,1), stride=1, padding=0)
    # branch 2 -> bottleneck + conv 3x3
    self.bottleneck1 = nn.Conv2d(in_channels=in_features, out_channels=bottleneck_size,
                                 kernel_size=(1,1), stride=1, padding=0)
    self.conv2 = nn.Conv2d(in_channels=bottleneck_size, out_channels=192,
                           kernel_size=(3,3), stride=1, padding=1)
    # branch 3 -> bottleneck + conv 5x5
    self.bottleneck2 = nn.Conv2d(in_features, bottleneck_size, (1,1),
                                 stride=1, padding=0)
    self.conv3 = nn.Conv2d(bottleneck_size, 96, (5,5),
                           stride=1, padding=2)
    # branch 4 -> max_pool + bottleneck
    self.pool = nn.MaxPool2d((3,3), stride=1, padding=1)
    self.bottleneck3 = nn.Conv2d(in_features, bottleneck_size, (1,1),
                                 stride=1, padding=0)
    # activation
    self.activation = nn.ReLU()

  def forward(self, x):
    module_input = x
    # branch 1
    out1 = self.activation(self.conv1(module_input))
    # branch 2
    out2 = self.activation(self.bottleneck1(module_input))
    out2 = self.activation(self.conv2(out2))
    # branch 3
    out3 = self.activation(self.bottleneck2(module_input))
    out3 = self.activation(self.conv3(out3))
    # branch 4
    out4 = self.pool(module_input)
    out4 = self.activation(self.bottleneck3(out4))
    # concatenation
    return_value = torch.cat((out1, out2, out3, out4), dim=1)
    return return_value

class ResidualBlock(nn.Module):
  def __init__(self, f):
    super(ResidualBlock, self).__init__()
    self.conv1 = nn.Conv2d(f, f//4, (1,1), stride=1, padding=0)
    self.conv2 = nn.Conv2d(f//4, f//4, (3,3), stride=1, padding=1)
    self.conv3 = nn.Conv2d(f//4, f, (1,1), stride=1, padding=0)
    
    self.bn1 = nn.BatchNorm2d(f//4)
    self.bn2 = nn.BatchNorm2d(f//4)
    self.bn3 = nn.BatchNorm2d(f)

    self.relu = nn.ReLU()

  def forward(self, x):
    inputs = x
    x = self.relu(self.bn1(self.conv1(x)))
    x = self.relu(self.bn2(self.conv2(x)))
    x = self.relu(self.bn3(self.conv3(x)))
    return inputs + x

output_size = len(classes)
learning_rate = 1e-2

model = nn.Sequential(
    nn.Conv2d(3, 32, (5,5), stride=2, padding=2),
    nn.ReLU(),
    nn.Conv2d(32, 64, (5,5), stride=2, padding=2),
    nn.ReLU(),
    InceptionModule(64, 16),
    InceptionModule(480-48),
    nn.AdaptiveAvgPool2d(1),
    nn.Flatten(),
    nn.Linear(480, 100)
).to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,
                            momentum=0.9, nesterov=True)

num_epoch = 50
eval_every = 5
best_accuracy = 0.

for epoch in range(num_epoch):
  model.train()
  print('Starting Epoch {}/{}...'.format(epoch+1, num_epoch))
  accuracy = train_epoch(model, optimizer, trainloader)
  print('Epoch {} - Accuracy: {:.2f}%'.format(epoch+1, accuracy))

  if epoch % eval_every == eval_every - 1: 
    model.eval()
    with torch.no_grad():
      print('Evaluating model...')
      test_accuracy = evaluate(model, testloader)
      print('Test accuracy: {:.2f}%'.format(test_accuracy))
      if test_accuracy > best_accuracy:
        best_accuracy = test_accuracy
        torch.save(model.state_dict(), './data/checkpoint.ckp')
        print('Saved checkpoint!')
  
print('Finished training')

model.eval()
with torch.no_grad():
  print('Evaluating model...loading best weigths')
  model.load_state_dict(torch.load('./data/checkpoint.ckp'))
  accuracy = evaluate(model, testloader)
  print('Test accuracy: {:.2f}%'.format(accuracy))

  print ('Showing qualitative results...')
  dataiter = iter(testloader)
  images, labels = dataiter.next()
  images = images.to(device)
  labels = labels.to(device)

  out = model(images)
  _, pred = torch.max(out, 1)

  imshow(torchvision.utils.make_grid(images.cpu()[:8] / 2 + 0.5))
  print('predicted labels: \t {}'.format([classes[p] for p in pred[:8]]))
  print('ground-truth labels: \t {}'.format([classes[l] for l in labels[:8]]))
