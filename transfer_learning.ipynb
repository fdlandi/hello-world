{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1DCa4xWd-eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJkUx1jfeKsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c0a32838-0955-454c-92ae-196c74aa355f"
      },
      "source": [
        "# To build an out of the box vgg network\n",
        "# 'pretrained = False' -> will need training from scratch\n",
        "vgg16 = torchvision.models.vgg16(pretrained=False)\n",
        "\n",
        "# Let's see what this model contains\n",
        "parameters_dict = dict(vgg16.named_parameters())\n",
        "parameters_name = parameters_dict.keys()\n",
        "parameters_values = parameters_dict.values()\n",
        "\n",
        "for par, val in zip(parameters_name, parameters_values):\n",
        "  print(\"{} -> {}\".format(par, list(val.shape)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.0.weight -> [64, 3, 3, 3]\n",
            "features.0.bias -> [64]\n",
            "features.2.weight -> [64, 64, 3, 3]\n",
            "features.2.bias -> [64]\n",
            "features.5.weight -> [128, 64, 3, 3]\n",
            "features.5.bias -> [128]\n",
            "features.7.weight -> [128, 128, 3, 3]\n",
            "features.7.bias -> [128]\n",
            "features.10.weight -> [256, 128, 3, 3]\n",
            "features.10.bias -> [256]\n",
            "features.12.weight -> [256, 256, 3, 3]\n",
            "features.12.bias -> [256]\n",
            "features.14.weight -> [256, 256, 3, 3]\n",
            "features.14.bias -> [256]\n",
            "features.17.weight -> [512, 256, 3, 3]\n",
            "features.17.bias -> [512]\n",
            "features.19.weight -> [512, 512, 3, 3]\n",
            "features.19.bias -> [512]\n",
            "features.21.weight -> [512, 512, 3, 3]\n",
            "features.21.bias -> [512]\n",
            "features.24.weight -> [512, 512, 3, 3]\n",
            "features.24.bias -> [512]\n",
            "features.26.weight -> [512, 512, 3, 3]\n",
            "features.26.bias -> [512]\n",
            "features.28.weight -> [512, 512, 3, 3]\n",
            "features.28.bias -> [512]\n",
            "classifier.0.weight -> [4096, 25088]\n",
            "classifier.0.bias -> [4096]\n",
            "classifier.3.weight -> [4096, 4096]\n",
            "classifier.3.bias -> [4096]\n",
            "classifier.6.weight -> [1000, 4096]\n",
            "classifier.6.bias -> [1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MXprzwvhmYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "34dcc4e7-9dac-4855-84d5-eda34685ec26"
      },
      "source": [
        "# what does the \"features\" block contain?\n",
        "# hint: \"features = feature extraction\"\n",
        "vgg16.features"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace=True)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (18): ReLU(inplace=True)\n",
              "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace=True)\n",
              "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (25): ReLU(inplace=True)\n",
              "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (27): ReLU(inplace=True)\n",
              "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9RXNVQ3iEU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ba7f65e2-b88c-4a57-ff24-c53fdd066530"
      },
      "source": [
        "vgg16.classifier"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hVzL2iciKWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76822ab6-ec9d-49d2-bd9a-91a3c04b8294"
      },
      "source": [
        "# How to get the last layer (classification layer)?\n",
        "vgg16.classifier[6]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHo1ETsPiWXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to change it for a new task?\n",
        "num_input = vgg16.classifier[6].in_features\n",
        "num_output = 10  # <- put here the number depending on your task\n",
        "vgg16.classifier[6] = torch.nn.Linear(in_features=num_input, out_features=num_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAUNYHrei0Z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f4bb8a6-83fa-4142-e781-6d7499d5d81a"
      },
      "source": [
        "# What does the last layer contains now?\n",
        "vgg16.classifier[6]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=10, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR19q1Mrix6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other networks available\n",
        "google_net = torchvision.models.googlenet(pretrained=False)\n",
        "resnet152 = torchvision.models.resnet152(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSYYYHYYjgEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f217acb8-4430-4bc0-cd99-7e1809964e22"
      },
      "source": [
        "# Downloading the weights pretrained on ImageNet together with the network\n",
        "# -> specify pretrained = True\n",
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Let's see what this model contains\n",
        "parameters_dict = dict(resnet18.named_parameters())\n",
        "parameters_name = parameters_dict.keys()\n",
        "parameters_values = parameters_dict.values()\n",
        "\n",
        "for par, val in zip(parameters_name, parameters_values):\n",
        "  print(\"{} -> {}\".format(par, list(val.shape)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight -> [64, 3, 7, 7]\n",
            "bn1.weight -> [64]\n",
            "bn1.bias -> [64]\n",
            "layer1.0.conv1.weight -> [64, 64, 3, 3]\n",
            "layer1.0.bn1.weight -> [64]\n",
            "layer1.0.bn1.bias -> [64]\n",
            "layer1.0.conv2.weight -> [64, 64, 3, 3]\n",
            "layer1.0.bn2.weight -> [64]\n",
            "layer1.0.bn2.bias -> [64]\n",
            "layer1.1.conv1.weight -> [64, 64, 3, 3]\n",
            "layer1.1.bn1.weight -> [64]\n",
            "layer1.1.bn1.bias -> [64]\n",
            "layer1.1.conv2.weight -> [64, 64, 3, 3]\n",
            "layer1.1.bn2.weight -> [64]\n",
            "layer1.1.bn2.bias -> [64]\n",
            "layer2.0.conv1.weight -> [128, 64, 3, 3]\n",
            "layer2.0.bn1.weight -> [128]\n",
            "layer2.0.bn1.bias -> [128]\n",
            "layer2.0.conv2.weight -> [128, 128, 3, 3]\n",
            "layer2.0.bn2.weight -> [128]\n",
            "layer2.0.bn2.bias -> [128]\n",
            "layer2.0.downsample.0.weight -> [128, 64, 1, 1]\n",
            "layer2.0.downsample.1.weight -> [128]\n",
            "layer2.0.downsample.1.bias -> [128]\n",
            "layer2.1.conv1.weight -> [128, 128, 3, 3]\n",
            "layer2.1.bn1.weight -> [128]\n",
            "layer2.1.bn1.bias -> [128]\n",
            "layer2.1.conv2.weight -> [128, 128, 3, 3]\n",
            "layer2.1.bn2.weight -> [128]\n",
            "layer2.1.bn2.bias -> [128]\n",
            "layer3.0.conv1.weight -> [256, 128, 3, 3]\n",
            "layer3.0.bn1.weight -> [256]\n",
            "layer3.0.bn1.bias -> [256]\n",
            "layer3.0.conv2.weight -> [256, 256, 3, 3]\n",
            "layer3.0.bn2.weight -> [256]\n",
            "layer3.0.bn2.bias -> [256]\n",
            "layer3.0.downsample.0.weight -> [256, 128, 1, 1]\n",
            "layer3.0.downsample.1.weight -> [256]\n",
            "layer3.0.downsample.1.bias -> [256]\n",
            "layer3.1.conv1.weight -> [256, 256, 3, 3]\n",
            "layer3.1.bn1.weight -> [256]\n",
            "layer3.1.bn1.bias -> [256]\n",
            "layer3.1.conv2.weight -> [256, 256, 3, 3]\n",
            "layer3.1.bn2.weight -> [256]\n",
            "layer3.1.bn2.bias -> [256]\n",
            "layer4.0.conv1.weight -> [512, 256, 3, 3]\n",
            "layer4.0.bn1.weight -> [512]\n",
            "layer4.0.bn1.bias -> [512]\n",
            "layer4.0.conv2.weight -> [512, 512, 3, 3]\n",
            "layer4.0.bn2.weight -> [512]\n",
            "layer4.0.bn2.bias -> [512]\n",
            "layer4.0.downsample.0.weight -> [512, 256, 1, 1]\n",
            "layer4.0.downsample.1.weight -> [512]\n",
            "layer4.0.downsample.1.bias -> [512]\n",
            "layer4.1.conv1.weight -> [512, 512, 3, 3]\n",
            "layer4.1.bn1.weight -> [512]\n",
            "layer4.1.bn1.bias -> [512]\n",
            "layer4.1.conv2.weight -> [512, 512, 3, 3]\n",
            "layer4.1.bn2.weight -> [512]\n",
            "layer4.1.bn2.bias -> [512]\n",
            "fc.weight -> [1000, 512]\n",
            "fc.bias -> [1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMjzcERAkN1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze all the layers in the network\n",
        "for layer in resnet18.parameters():\n",
        "  layer.requires_grad = False "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphSmPMekhs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e660495e-07d9-42f7-ade1-bfbd84c8018e"
      },
      "source": [
        "# To re-activate the autograd module for a layer\n",
        "# and make it trainable again\n",
        "resnet18.fc.requires_grad_(True)\n",
        "\n",
        "for par, val in zip(parameters_name, parameters_values):\n",
        "  print(\"{} \\t-> {}\".format(par, val.requires_grad))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight \t-> False\n",
            "bn1.weight \t-> False\n",
            "bn1.bias \t-> False\n",
            "layer1.0.conv1.weight \t-> False\n",
            "layer1.0.bn1.weight \t-> False\n",
            "layer1.0.bn1.bias \t-> False\n",
            "layer1.0.conv2.weight \t-> False\n",
            "layer1.0.bn2.weight \t-> False\n",
            "layer1.0.bn2.bias \t-> False\n",
            "layer1.1.conv1.weight \t-> False\n",
            "layer1.1.bn1.weight \t-> False\n",
            "layer1.1.bn1.bias \t-> False\n",
            "layer1.1.conv2.weight \t-> False\n",
            "layer1.1.bn2.weight \t-> False\n",
            "layer1.1.bn2.bias \t-> False\n",
            "layer2.0.conv1.weight \t-> False\n",
            "layer2.0.bn1.weight \t-> False\n",
            "layer2.0.bn1.bias \t-> False\n",
            "layer2.0.conv2.weight \t-> False\n",
            "layer2.0.bn2.weight \t-> False\n",
            "layer2.0.bn2.bias \t-> False\n",
            "layer2.0.downsample.0.weight \t-> False\n",
            "layer2.0.downsample.1.weight \t-> False\n",
            "layer2.0.downsample.1.bias \t-> False\n",
            "layer2.1.conv1.weight \t-> False\n",
            "layer2.1.bn1.weight \t-> False\n",
            "layer2.1.bn1.bias \t-> False\n",
            "layer2.1.conv2.weight \t-> False\n",
            "layer2.1.bn2.weight \t-> False\n",
            "layer2.1.bn2.bias \t-> False\n",
            "layer3.0.conv1.weight \t-> False\n",
            "layer3.0.bn1.weight \t-> False\n",
            "layer3.0.bn1.bias \t-> False\n",
            "layer3.0.conv2.weight \t-> False\n",
            "layer3.0.bn2.weight \t-> False\n",
            "layer3.0.bn2.bias \t-> False\n",
            "layer3.0.downsample.0.weight \t-> False\n",
            "layer3.0.downsample.1.weight \t-> False\n",
            "layer3.0.downsample.1.bias \t-> False\n",
            "layer3.1.conv1.weight \t-> False\n",
            "layer3.1.bn1.weight \t-> False\n",
            "layer3.1.bn1.bias \t-> False\n",
            "layer3.1.conv2.weight \t-> False\n",
            "layer3.1.bn2.weight \t-> False\n",
            "layer3.1.bn2.bias \t-> False\n",
            "layer4.0.conv1.weight \t-> False\n",
            "layer4.0.bn1.weight \t-> False\n",
            "layer4.0.bn1.bias \t-> False\n",
            "layer4.0.conv2.weight \t-> False\n",
            "layer4.0.bn2.weight \t-> False\n",
            "layer4.0.bn2.bias \t-> False\n",
            "layer4.0.downsample.0.weight \t-> False\n",
            "layer4.0.downsample.1.weight \t-> False\n",
            "layer4.0.downsample.1.bias \t-> False\n",
            "layer4.1.conv1.weight \t-> False\n",
            "layer4.1.bn1.weight \t-> False\n",
            "layer4.1.bn1.bias \t-> False\n",
            "layer4.1.conv2.weight \t-> False\n",
            "layer4.1.bn2.weight \t-> False\n",
            "layer4.1.bn2.bias \t-> False\n",
            "fc.weight \t-> True\n",
            "fc.bias \t-> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNfw6ChemX3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4879d4fc-807f-4fb9-b726-6a835652acc8"
      },
      "source": [
        "# We can re-initialize the fc layer to fine-tune the network on a new task\n",
        "# NB: New layers always have \"requires_grad = True\"\n",
        "resnet18.fc = torch.nn.Linear(in_features=resnet18.fc.in_features,\n",
        "                              out_features=10)\n",
        "\n",
        "print(resnet18.fc.weight.requires_grad, resnet18.fc.bias.requires_grad)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True True\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}